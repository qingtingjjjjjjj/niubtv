name: Scrape Live Streams

on:
  schedule:
    - cron: '0 3 * * *'  # 每天 UTC 时间 03:00（即美国东部夏令时 23:00）
  workflow_dispatch: # 允许手动触发

jobs:
  scrape:
    runs-on: ubuntu-latest

    steps:
    - name: Checkout repository
      uses: actions/checkout@v3  # 确保检出代码仓库

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.x'  # 设置 Python 版本为 3.x

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip  # 升级 pip
        pip install aiohttp  # 安装 aiohttp
        pip install beautifulsoup4  # 安装 BeautifulSoup 库
        pip install -r requirements.txt  # 安装 requirements.txt 中的其他依赖

    - name: Create live_streams directory
      run: |
        mkdir -p live_streams  # 自动创建 live_streams 目录

    - name: Run scraper
      run: |
        python scraper.py  # 执行你的爬虫脚本

    - name: List files in the repository
      run: ls -R  # 列出所有文件，确认 live_streams/ 目录是否存在

    - name: Check git status
      run: git status  # 查看 git 状态，确保文件变动

    - name: Commit and push changes
      uses: EndBug/add-and-commit@v9  # 使用 GitHub Actions 提交更改
      with:
        author_name: 'GitHub Actions'  # 提交者名称
        author_email: 'actions@github.com'  # 提交者邮箱
        message: 'Update live stream data'  # 提交信息
        add: 'live_streams/*'  # 提交 live_streams 目录下的所有更改
